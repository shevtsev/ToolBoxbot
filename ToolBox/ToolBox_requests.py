import telebot, os, json, concurrent.futures, time, logging
from random import randint
from telebot import types
from md2tgmd import escape
from BaseSettings.AuxiliaryClasses import PromptsCompressor, keyboards
from ToolBox_n_networks import neural_networks

# Class initialization
pc = PromptsCompressor()

logging.basicConfig(filename='out.log', level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

#Main functions class
class ToolBox(keyboards, neural_networks):
    def __init__(self):
        # Start buttons
        self.name = ["Ð¢ÐµÐºÑÑ‚ ðŸ“", "Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ ðŸŽ¨", "Ð¡Ð²Ð¾Ð±Ð¾Ð´Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ ðŸ—½", "Ð¢Ð°Ñ€Ð¸Ñ„Ñ‹ ðŸ’¸"]
        self.data = ["text", "images", "free", "tariff"]

        # Promts texts load
        with open("ToolBox/BaseSettings/prompts.json", 'r') as file:
            self.prompts_text = json.load(file)

        # Telegram bot initialization
        self.bot = telebot.TeleBot(token=os.environ['TOKEN'])
        # Inline keyboard blank lambda
        self.keyboard_blank = lambda self, name, data: super()._keyboard_two_blank(data, name)
        # Markup keyboard
        self.reply_keyboard = lambda self, name: super()._reply_keyboard(name)
        # Request delay
        self.__delay        = lambda message, self=self: self.bot.send_message(message.chat.id, "ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ, ÑÑ‚Ð¾ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð·Ð°Ð½ÑÑ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐµÐºÑƒÐ½Ð´ . . .", parse_mode='html')  
        # Start request
        self.start_request  = lambda message, self=self: self.bot.send_message(message.chat.id, self.prompts_text['hello'], reply_markup=self.keyboard_blank(self, self.name, self.data), parse_mode='html')
        # Restart request
        self.restart        = lambda message, self=self: self.bot.send_message(message.chat.id, "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð½ÑƒÐ¶Ð½ÑƒÑŽ Ð²Ð°Ð¼ Ð·Ð°Ð´Ð°Ñ‡Ñƒ", reply_markup=self.keyboard_blank(self, self.name, self.data), parse_mode='html')
        # Restart murkup
        self.restart_markup = lambda message, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð½ÑƒÐ¶Ð½ÑƒÑŽ Ð²Ð°Ð¼ Ð·Ð°Ð´Ð°Ñ‡Ñƒ", reply_markup=self.keyboard_blank(self, self.name, self.data), parse_mode='html')
        # One text request
        self.OneTextArea    = lambda message, ind, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text=self.prompts_text['text_list'][ind][0], reply_markup=self.keyboard_blank(self, ["ÐÐ°Ð·Ð°Ð´"], ["text_exit"]))
        # Some texts request
        self.SomeTextsArea  = lambda message, ind, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text=self.prompts_text['few_texts_list'][ind][0], reply_markup=self.keyboard_blank(self, ["ÐÐ°Ð·Ð°Ð´"], ["text_exit"]))
        # Image size on
        self.ImageSize_off  = lambda message, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="Ð’ ÑÑ‚Ð¾Ð¼ Ð¼ÐµÐ½ÑŽ Ð²Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ Ð²Ð²Ð¾Ð´Ð¸Ð¼Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð° (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¾).", reply_markup=self.keyboard_blank(self, ["9:16", "1:1", "16:9", "Ð£Ð»ÑƒÑ‡ÑˆÐ°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ‹", "Ð’ Ð¼ÐµÐ½ÑŽ"], ["576x1024", "1024x1024", "1024x576", "improve_prompts_off", "exit"]), parse_mode='html')
        # Image size off
        self.ImageSize_on   = lambda message, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="Ð’ ÑÑ‚Ð¾Ð¼ Ð¼ÐµÐ½ÑŽ Ð²Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ Ð²Ð²Ð¾Ð´Ð¸Ð¼Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð° (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¾).", reply_markup=self.keyboard_blank(self, ["9:16", "1:1", "16:9", "Ð£Ð»ÑƒÑ‡ÑˆÐ°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ‹âœ…", "Ð’ Ð¼ÐµÐ½ÑŽ"], ["576x1024", "1024x1024", "1024x576", "improve_prompts_on", "exit"]), parse_mode='html')
        # Image request
        self.ImageArea      = lambda message, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ ðŸ–¼", reply_markup=self.keyboard_blank(self, ["Ð’ Ð¼ÐµÐ½ÑŽ"], ["exit"]), parse_mode='html')
        # Image change
        self.ImageChange    = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ", reply_markup=self.keyboard_blank(self, ["Ð£Ð»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ ðŸª„", "ðŸ”", "ÐÐ¾Ð²Ð°Ñ ðŸ–¼", "Ð’ Ð¼ÐµÐ½ÑŽ"], ["upscale", "regenerate", "images", "exit"]), parse_mode='html')
        # Message before upscale
        self.BeforeUpscale  = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ", reply_markup=self.keyboard_blank(self, ["ðŸ”", "ÐÐ¾Ð²Ð°Ñ ðŸ–¼", "Ð’ Ð¼ÐµÐ½ÑŽ"], ["regenerate", "images", "exit"]), parse_mode='html')
        # Free mode request
        self.FreeArea       = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñ", reply_markup=self.reply_keyboard(self, ["Ð’ Ð¼ÐµÐ½ÑŽ"]), parse_mode='html')
        # Tariff request
        self.TariffArea     = lambda message, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="Ð¢Ð°Ñ€Ð¸Ñ„Ñ‹", reply_markup=self.keyboard_blank(self, ["BASIC", "PRO", "ÐŸÑ€Ð¾Ð¼Ð¾ÐºÐ¾Ð´", "Ð’ Ð¼ÐµÐ½ÑŽ", "Ð ÐµÑ„ÐµÑ€Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°"], ["basic", "pro", "promo", "exit", "ref"]))
        # Tariffs area exit
        self.TariffExit     = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="Ð¢Ð°Ñ€Ð¸Ñ„Ñ‹", reply_markup=self.keyboard_blank(self, ["BASIC", "PRO", "ÐŸÑ€Ð¾Ð¼Ð¾ÐºÐ¾Ð´", "Ð’ Ð¼ÐµÐ½ÑŽ", "Ð ÐµÑ„ÐµÑ€Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°"], ["basic", "pro", "promo", "exit", "ref"]))
        # End tariff
        self.TarrifEnd      = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="Ð£ Ð²Ð°Ñ Ð·Ð°ÐºÐ¾Ð½Ñ‡Ð¸Ð»Ð¸ÑÑŒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹, Ð½Ð¾ Ð²Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð¿Ñ€Ð¾Ð´Ð»Ð¸Ñ‚ÑŒ Ð²Ð°Ñˆ Ñ‚Ð°Ñ€Ð¸Ñ„.", reply_markup=self.keyboard_blank(self, ["BASIC", "PRO", "ÐŸÑ€Ð¾Ð¼Ð¾ÐºÐ¾Ð´", "Ð’ Ð¼ÐµÐ½ÑŽ", "Ð ÐµÑ„ÐµÑ€Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°"], ["basic", "pro", "promo", "ref", "exit"]))
        # Free tariff end
        self.FreeTariffEnd  = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="Ð›Ð¸Ð¼Ð¸Ñ‚ Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð², ÑƒÐ²Ñ‹, Ð¸ÑÑ‡ÐµÑ€Ð¿Ð°Ð½ðŸ˜¢ ÐÐ¾ Ð²Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ð¾Ð´Ð¸Ð½ Ð¸Ð· Ð½Ð°ÑˆÐ¸Ñ… Ð¿Ð»Ð°Ñ‚Ð½Ñ‹Ñ… Ñ‚Ð°Ñ€Ð¸Ñ„Ð¾Ð². ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð° Ð½Ð¸Ñ… Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ", reply_markup=self.keyboard_blank(self, ["BASIC", "PRO", "ÐŸÑ€Ð¾Ð¼Ð¾ÐºÐ¾Ð´", "Ð’ Ð¼ÐµÐ½ÑŽ", "Ð ÐµÑ„ÐµÑ€Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°"], ["basic", "pro", "promo", "exit", "ref"]))
        # Select one or some texts
        self.SomeTexts      = lambda message, ind, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="Ð¥Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ Ð¾Ð´Ð¸Ð½ Ñ‚ÐµÐºÑÑ‚ Ð¸Ð»Ð¸ ÑÑ€Ð°Ð·Ñƒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾?", reply_markup=self.keyboard_blank(self, ["ÐžÐ´Ð¸Ð½", "ÐÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾", "ÐÐ°Ð·Ð°Ð´"], [f"one_{ind}", f"some_{ind}", "text_exit"]))
        
#Private        
    # GPT 4o mini processing
    def __gpt_4o_mini(self, prompt: list[dict], message, temperature: float = 0.5, top_p: float = 0.85) -> tuple[dict[str, str], int, int]:
        send = self.__delay(message)
        response, incoming_tokens, outgoing_tokens = super()._free_gpt_4o_mini(prompt=prompt, temperature=temperature, top_p=top_p)
        response = escape(response)
        for i in range(0, len(response), 4096):
            chunk = response[i:i+4096]
            if i == 0:
                self.bot.edit_message_text(chat_id=send.chat.id, message_id=send.message_id, text=chunk, parse_mode='MarkdownV2')
            else:
                self.bot.send_message(chat_id=send.chat.id, text=chunk, parse_mode='MarkdownV2')
        return response, incoming_tokens, outgoing_tokens
        
    # Mistral large processing
    def mistral_large(self, prompt: str, temperature: float = 0.6, top_p: float = 0.85) -> str:
        response, incoming_tokens, outgoing_tokens = super()._mistral_large_2407(prompt=[{"role": "user", "content": prompt}], temperature=temperature, top_p=top_p)
        return response
    
    # FLUX schnell processing
    def __FLUX_schnell(self, prompt: str, size: list[int], message, seed: int, num_inference_steps: int)-> None:
        send = self.__delay(message)
        error_cnt = 0
        while error_cnt <= 3:
            photo = super()._FLUX_schnell(prompt, size, seed, num_inference_steps)
            if photo is None:
                logger.error(f"Response to FLUX schnell was unsuccessful, trying count: {error_cnt}")
                error_cnt+=1
            else:
                break
        if photo:
            self.bot.send_photo(chat_id=message.chat.id, photo=photo)
            try:
                return self.bot.delete_message(chat_id=send.chat.id, message_id=send.message_id)
            except Exception as e:
                logger.error(f"Error while deleting message: {e}")
        return self.bot.edit_message_text(chat_id=send.chat.id, message_id=send.message_id, text="ÐŸÑ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¾Ð·Ð½Ð¸ÐºÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð·Ð¶Ðµ")

#Public
    # Text types
    def Text_types(self, message):
        name = ["ÐšÐ¾Ð¼Ð¼ÐµÑ€Ñ‡ÐµÑÐºÐ¸Ð¹  ðŸ›ï¸", "ÐšÐ¾Ð½Ñ‚ÐµÐ½Ñ‚-Ð¿Ð»Ð°Ð½ ðŸ“‹", "Ð¡ÑƒÐ¼Ð¼Ð°Ñ€Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚ ðŸ“š", "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð´Ð»Ñ Ð±Ð»Ð¾Ð³Ð° ðŸ’»", "Ð›Ð¾Ð½Ð³Ñ€Ð¸Ð´ ðŸ“‘", "SMM ðŸ“±",
                "Ð‘Ñ€ÐµÐ¹Ð½ÑˆÑ‚Ð¾Ñ€Ð¼ ðŸ’¡", "Ð ÐµÐºÐ»Ð°Ð¼Ð½Ñ‹Ðµ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ñ‹ ðŸ“º", "Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ðŸ”", "SEO ðŸŒ", "ÐÐ¾Ð²Ð¾ÑÑ‚ÑŒ ðŸ“°", "Ð ÐµÐ´Ð°ÐºÑ‚ÑƒÑ€Ð° ðŸ“", "Ð’ Ð¼ÐµÐ½ÑŽ"]
        data = ["comm-text", "content-plan", "summarization", "blog", "longrid", "smm-text", "brainst-text", "advertising-text",
                "headlines-text", "seo-text", "news", "editing", "exit"]
        return self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="ðŸ“ Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‚Ð¸Ð¿ Ñ‚ÐµÐºÑÑ‚Ð°", reply_markup=self.keyboard_blank(self, name, data))
    
    # Tariffs
    # Basic tariff
    def Basic_tariff(self, message):
        keyboard = types.InlineKeyboardMarkup()
        keyboard.add(types.InlineKeyboardButton("ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ñ‚Ð°Ñ€Ð¸Ñ„ BASIC", pay=True))
        keyboard.add(types.InlineKeyboardButton("Ðš Ñ‚Ð°Ñ€Ð¸Ñ„Ð°Ð¼", callback_data="tariff_exit"))
        price = [types.LabeledPrice(label='BASIC', amount=60*100)]
        try:
            self.bot.delete_message(chat_id=message.chat.id, message_id=message.message_id)
        except Exception as e:
            logger.error(f"Error while deleting message: {e}")
        self.bot.send_invoice(chat_id=message.chat.id, title = 'BASIC',
            description = "Ð‘ÐµÐ·Ð»Ð¸Ð¼Ð¸Ñ‚Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð°, Ð² Ñ‚Ð¾Ð¼ Ñ‡Ð¸ÑÐ»Ðµ Ð¿Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°Ð¼.",
            invoice_payload = 'basic_invoice_payload',
            start_parameter='subscription',
            provider_token = os.environ['PROVIDE_TOKEN'],
            currency='RUB', prices=price, reply_markup=keyboard)
    
    # Pro tariff
    def Pro_tariff(self, message):
        keyboard = types.InlineKeyboardMarkup()
        keyboard.add(types.InlineKeyboardButton("ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ñ‚Ð°Ñ€Ð¸Ñ„ PRO", pay=True))
        keyboard.add(types.InlineKeyboardButton("Ðš Ñ‚Ð°Ñ€Ð¸Ñ„Ð°Ð¼", callback_data="tariff_exit"))
        price = [types.LabeledPrice(label='PRO', amount=100*100)]
        try:
            self.bot.delete_message(chat_id=message.chat.id, message_id=message.message_id)
        except Exception as e:
            logger.error(f"Error while deleting message: {e}")
        self.bot.send_invoice(chat_id=message.chat.id, title = 'PRO',
            description = "Ð‘ÐµÐ·Ð»Ð¸Ð¼Ð¸Ñ‚Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° (Ð² Ñ‚Ð¾Ð¼ Ñ‡Ð¸ÑÐ»Ðµ Ð¿Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°Ð¼) Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹.",
            invoice_payload = 'pro_invoice_payload',
            start_parameter='subscription',
            provider_token = os.environ['PROVIDE_TOKEN'],
            currency='RUB', prices=price, reply_markup=keyboard)
        
    # One text processing
    def TextCommands(self, message, ind: int):
        info = []
        incoming_tokens = 0; outgoing_tokens = 0
        info.append(message.text)
        for i in range(1, len(self.prompts_text['text_list'][ind])):
            msg = self.bot.send_message(chat_id=message.chat.id, text=self.prompts_text['text_list'][ind][i])
            param = None

            def Param_next_step(message):
                nonlocal info, param
                param = message.text
                info.append(param)

            self.bot.register_next_step_handler(msg, Param_next_step)
            while param is None:
                time.sleep(0.5)
        prompt = pc.get_prompt(ind=ind, info=info)
        response, incoming_tokens, outgoing_tokens = self.__gpt_4o_mini(prompt=[{ "role": "user", "content": prompt }], message=message)
        self.restart(message)
        return incoming_tokens, outgoing_tokens, 1
    
    # Some texts processing
    def SomeTextsCommand(self, message, ind: int, tokens: dict[str, int]):
        n = int(message.text)
        text_buttons = [
            "comm-text", "content-plan", "summarization",
            "blog", "longrid", "smm-text", "brainst-text",
            "advertising-text", "headlines-text", "seo-text",
            "news", "editing"
        ]
        ans = []
        avalible = [text_buttons.index(el) for el in [
                                                    "comm-text", "blog", "longrid", "smm-text",
                                                    "advertising-text", "seo-text", "news"
                                                    ]]

        for i in range(n):
            ans.append([])
            if "TEXT" in pc.commands_size[ind]:
                msg = self.bot.send_message(chat_id=message.chat.id, text=f"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ñ‚ÐµÐºÑÑ‚ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ° {i+1}")
                text = None
                def Text_next_step(message):
                    nonlocal text, ans
                    text = message.text
                    ans[i].append(text)
                self.bot.register_next_step_handler(msg, Text_next_step)
                while text is None:
                    time.sleep(0.5)
        
        index = avalible.index(ind)
        for el in range(1, len(self.prompts_text["few_texts_list"][index])):
            msg = self.bot.send_message(chat_id=message.chat.id, text=self.prompts_text["few_texts_list"][index][el])
            params = None
            def Params_addition(message):
                nonlocal params, ans
                params = message.text
                params = params.split(';')
                if len(params) < len(pc.commands_size[ind]):
                    while len(params) < len(pc.commands_size[ind]):
                        params.append(None)
                param = params[0]
                [ans[i].append(param) if params[i] is None else ans[i].append(params[i]) for i in range(len(ans))]
            self.bot.register_next_step_handler(msg, Params_addition)
            while params is None:
                time.sleep(0.5)

        incoming_tokens = 0; outgoing_tokens = 0
        def process_prompt(i):
            nonlocal incoming_tokens, outgoing_tokens
            prompt = pc.get_prompt(ind=ind, info=ans[i])
            if tokens['incoming_tokens'] - incoming_tokens > 0 and tokens['outgoing_tokens'] - outgoing_tokens > 0 or tokens['free_requests'] - i > 0:
                response, in_tokens, out_tokens = self.__gpt_4o_mini(prompt=[{"role": "user", "content": prompt}], message=message)
                return in_tokens, out_tokens
            return 0, 0
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            results = list(executor.map(process_prompt, range(n)))
        
        for in_tokens, out_tokens in results:
            incoming_tokens += in_tokens
            outgoing_tokens += out_tokens
        
        self.restart(message)
        return incoming_tokens, outgoing_tokens, n
    
    # Images processing
    def ImageCommand(self, message, prompt: str, size: list[int]):
        seed = randint(1, 1000000)
        self.__FLUX_schnell(prompt=prompt, size=size, message=message, seed=seed, num_inference_steps=4)
        self.ImageChange(message)
        return seed
    
    # Image regeneration and upscaling
    def Image_Regen_And_Upscale(self, message, prompt: str, size: list[int], seed, num_inference_steps=4):
        return self.__FLUX_schnell(prompt=prompt, size=size, message=message, seed=seed, num_inference_steps=num_inference_steps)
    
    # Free mode processing
    def FreeCommand(self, message, prompts: list[str]):
        response, incoming_tokens, outgoing_tokens = self.__gpt_4o_mini(prompt=prompts, message=message, temperature=0.7, top_p=0.85)
        prompts.append({"content": response, "role": "assistant"})
        return incoming_tokens, outgoing_tokens, prompts