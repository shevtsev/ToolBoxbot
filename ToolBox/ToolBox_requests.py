import telebot, os, json, concurrent.futures, time
from random import randint
from telebot import types
from md2tgmd import escape
from BaseSettings.AuxiliaryClasses import PromptsCompressor, keyboards
from ToolBox_n_networks import neural_networks

# Class initialization
pc = PromptsCompressor()

#Main functions class
class ToolBox(keyboards, neural_networks):
    def __init__(self):
        # Start buttons
        self.name = ["–¢–µ–∫—Å—Ç üìù", "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è üé®", "–°–≤–æ–±–æ–¥–Ω—ã–π —Ä–µ–∂–∏–º üóΩ", "–¢–∞—Ä–∏—Ñ—ã üí∏"]
        self.data = ["text", "images", "free", "tariff"]

        # Promts texts load
        with open("ToolBox/BaseSettings/prompts.json", 'r') as file:
            self.prompts_text = json.load(file)

        # Telegram bot initialization
        self.bot = telebot.TeleBot(token=os.environ['TOKEN'])
        # Inline keyboard blank lambda
        self.keyboard_blank = lambda self, name, data: super()._keyboard_two_blank(data, name)
        # Markup keyboard
        self.reply_keyboard = lambda self, name: super()._reply_keyboard(name)
        # Request delay
        self.__delay        = lambda message, self=self: self.bot.send_message(message.chat.id, "–ü–æ–¥–æ–∂–¥–∏—Ç–µ, —ç—Ç–æ –¥–æ–ª–∂–Ω–æ –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥ . . .", parse_mode='html')  
        # Start request
        self.start_request  = lambda message, self=self: self.bot.send_message(message.chat.id, self.prompts_text['hello'], reply_markup=self.keyboard_blank(self, self.name, self.data), parse_mode='html')
        # Restart request
        self.restart        = lambda message, self=self: self.bot.send_message(message.chat.id, "–í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω—É—é –≤–∞–º –∑–∞–¥–∞—á—É", reply_markup=self.keyboard_blank(self, self.name, self.data), parse_mode='html')
        # Restart murkup
        self.restart_markup = lambda message, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="–í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω—É—é –≤–∞–º –∑–∞–¥–∞—á—É", reply_markup=self.keyboard_blank(self, self.name, self.data), parse_mode='html')
        # One text request
        self.OneTextArea    = lambda message, ind, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text=self.prompts_text['text_list'][ind][0], reply_markup=self.keyboard_blank(self, ["–ù–∞–∑–∞–¥"], ["text_exit"]))
        # Some texts request
        self.SomeTextsArea  = lambda message, ind, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text=self.prompts_text['few_texts_list'][ind][0], reply_markup=self.keyboard_blank(self, ["–ù–∞–∑–∞–¥"], ["text_exit"]))
        # Image size on
        self.ImageSize_off  = lambda message, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="–í —ç—Ç–æ–º –º–µ–Ω—é –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –≤–≤–æ–¥–∏–º–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–∫–ª—é—á–µ–Ω–æ).", reply_markup=self.keyboard_blank(self, ["9:16", "1:1", "16:9", "–£–ª—É—á—à–∞—Ç—å –ø—Ä–æ–º–ø—Ç—ã", "–í –º–µ–Ω—é"], ["576x1024", "1024x1024", "1024x576", "improve_prompts_off", "exit"]), parse_mode='html')
        # Image size off
        self.ImageSize_on   = lambda message, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="–í —ç—Ç–æ–º –º–µ–Ω—é –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –≤–≤–æ–¥–∏–º–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–∫–ª—é—á–µ–Ω–æ).", reply_markup=self.keyboard_blank(self, ["9:16", "1:1", "16:9", "–£–ª—É—á—à–∞—Ç—å –ø—Ä–æ–º–ø—Ç—ã‚úÖ", "–í –º–µ–Ω—é"], ["576x1024", "1024x1024", "1024x576", "improve_prompts_on", "exit"]), parse_mode='html')
        # Image request
        self.ImageArea      = lambda message, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π üñº", reply_markup=self.keyboard_blank(self, ["–í –º–µ–Ω—é"], ["exit"]), parse_mode='html')
        # Image change
        self.ImageChange    = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="–í—ã–±–µ—Ä–∏—Ç–µ —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ", reply_markup=self.keyboard_blank(self, ["–£–ª—É—á—à–∏—Ç—å ü™Ñ", "üîÅ", "–ù–æ–≤–∞—è üñº", "–í –º–µ–Ω—é"], ["upscale", "regenerate", "images", "exit"]), parse_mode='html')
        # Message before upscale
        self.BeforeUpscale  = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="–í—ã–±–µ—Ä–∏—Ç–µ —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ", reply_markup=self.keyboard_blank(self, ["üîÅ", "–ù–æ–≤–∞—è üñº", "–í –º–µ–Ω—é"], ["regenerate", "images", "exit"]), parse_mode='html')
        # Free mode request
        self.FreeArea       = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å", reply_markup=self.reply_keyboard(self, ["–í –º–µ–Ω—é"]), parse_mode='html')
        # Tariff request
        self.TariffArea     = lambda message, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="–¢–∞—Ä–∏—Ñ—ã", reply_markup=self.keyboard_blank(self, ["BASIC", "PRO", "–ü—Ä–æ–º–æ–∫–æ–¥", "–í –º–µ–Ω—é", "–†–µ—Ñ–µ—Ä–∞–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞"], ["basic", "pro", "promo", "exit", "ref"]))
        # Tariffs area exit
        self.TariffExit     = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="–¢–∞—Ä–∏—Ñ—ã", reply_markup=self.keyboard_blank(self, ["BASIC", "PRO", "–ü—Ä–æ–º–æ–∫–æ–¥", "–í –º–µ–Ω—é", "–†–µ—Ñ–µ—Ä–∞–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞"], ["basic", "pro", "promo", "exit", "ref"]))
        # End tariff
        self.TarrifEnd      = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="–£ –≤–∞—Å –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å –∑–∞–ø—Ä–æ—Å—ã, –Ω–æ –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–ª–∏—Ç—å –≤–∞—à —Ç–∞—Ä–∏—Ñ.", reply_markup=self.keyboard_blank(self, ["BASIC", "PRO", "–ü—Ä–æ–º–æ–∫–æ–¥", "–í –º–µ–Ω—é", "–†–µ—Ñ–µ—Ä–∞–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞"], ["basic", "pro", "promo", "ref", "exit"]))
        # Free tariff end
        self.FreeTariffEnd  = lambda message, self=self: self.bot.send_message(chat_id=message.chat.id, text="–õ–∏–º–∏—Ç –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, —É–≤—ã, –∏—Å—á–µ—Ä–ø–∞–Ωüò¢ –ù–æ –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –æ–¥–∏–Ω –∏–∑ –Ω–∞—à–∏—Ö –ø–ª–∞—Ç–Ω—ã—Ö —Ç–∞—Ä–∏—Ñ–æ–≤. –ü—Ä–æ—Å—Ç–æ –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –Ω–∏—Ö –∏ –ø–æ–ª—É—á–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ", reply_markup=self.keyboard_blank(self, ["BASIC", "PRO", "–ü—Ä–æ–º–æ–∫–æ–¥", "–í –º–µ–Ω—é", "–†–µ—Ñ–µ—Ä–∞–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞"], ["basic", "pro", "promo", "exit", "ref"]))
        # Select one or some texts
        self.SomeTexts      = lambda message, ind, self=self: self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="–•–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç –∏–ª–∏ —Å—Ä–∞–∑—É –Ω–µ—Å–∫–æ–ª—å–∫–æ?", reply_markup=self.keyboard_blank(self, ["–û–¥–∏–Ω", "–ù–µ—Å–∫–æ–ª—å–∫–æ", "–ù–∞–∑–∞–¥"], [f"one_{ind}", f"some_{ind}", "text_exit"]))
        
#Private        
    # GPT 4o mini processing
    def __gpt_4o_mini(self, prompt: list[dict], message, temperature: float = 0.5, top_p: float = 0.85) -> tuple[dict[str, str], int, int]:
        send = self.__delay(message)
        response, incoming_tokens, outgoing_tokens = super()._free_gpt_4o_mini(prompt=prompt, temperature=temperature, top_p=top_p)
        response = escape(response)
        for i in range(0, len(response), 4096):
            chunk = response[i:i+4096]
            if i == 0:
                self.bot.edit_message_text(chat_id=send.chat.id, message_id=send.message_id, text=chunk, parse_mode='MarkdownV2')
            else:
                self.bot.send_message(chat_id=send.chat.id, text=chunk, parse_mode='MarkdownV2')
        return response, incoming_tokens, outgoing_tokens
        
    # Mistral large processing
    def mistral_large(self, prompt: str, temperature: float = 0.6, top_p: float = 0.85) -> tuple[str, int, int]:
        response, incoming_tokens, outgoing_tokens = super()._mistral_large_2407(prompt=[{"role": "user", "content": prompt}], temperature=temperature, top_p=top_p)
        return response
    
    # FLUX schnell processing
    def __FLUX_schnell(self, prompt: str, size: list[int], message, seed: int, num_inference_steps: int)-> None:
        send = self.__delay(message)
        while True:
            try:
                photo = super()._FLUX_schnell(prompt, size, seed, num_inference_steps)
            except:
                continue
            else:
                break
        if photo:
            self.bot.send_photo(chat_id=message.chat.id, photo=photo)
            return self.bot.delete_message(chat_id=send.chat.id, message_id=send.message_id)
        self.bot.edit_message_text(chat_id=send.chat.id, message_id=send.message_id, text="–ü—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–∑–∂–µ")

#Public
    # Text types
    def Text_types(self, message):
        name = ["–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π  üõçÔ∏è", "–ö–æ–Ω—Ç–µ–Ω—Ç-–ø–ª–∞–Ω üìã", "–°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç üìö", "–°—Ç–∞—Ç—å—è –¥–ª—è –±–ª–æ–≥–∞ üíª", "–õ–æ–Ω–≥—Ä–∏–¥ üìë", "SMM üì±",
                "–ë—Ä–µ–π–Ω—à—Ç–æ—Ä–º üí°", "–†–µ–∫–ª–∞–º–Ω—ã–µ –∫—Ä–µ–∞—Ç–∏–≤—ã üì∫", "–ó–∞–≥–æ–ª–æ–≤–∫–∏ üîç", "SEO üåê", "–ù–æ–≤–æ—Å—Ç—å üì∞", "–†–µ–¥–∞–∫—Ç—É—Ä–∞ üìù", "–í –º–µ–Ω—é"]
        data = ["comm-text", "content-plan", "summarization", "blog", "longrid", "smm-text", "brainst-text", "advertising-text",
                "headlines-text", "seo-text", "news", "editing", "exit"]
        return self.bot.edit_message_text(chat_id=message.chat.id, message_id=message.message_id, text="üìù –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø —Ç–µ–∫—Å—Ç–∞", reply_markup=self.keyboard_blank(self, name, data))
    
    # Tariffs
    # Basic tariff
    def Basic_tariff(self, message):
        keyboard = types.InlineKeyboardMarkup()
        keyboard.add(types.InlineKeyboardButton("–ü–æ–¥–∫–ª—é—á–∏—Ç—å —Ç–∞—Ä–∏—Ñ BASIC", pay=True))
        keyboard.add(types.InlineKeyboardButton("–ö —Ç–∞—Ä–∏—Ñ–∞–º", callback_data="tariff_exit"))
        price = [types.LabeledPrice(label='BASIC', amount=60*100)]
        self.bot.delete_message(chat_id=message.chat.id, message_id=message.message_id)
        self.bot.send_invoice(chat_id=message.chat.id, title = 'BASIC',
            description = "–ë–µ–∑–ª–∏–º–∏—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, –≤ —Ç–æ–º —á–∏—Å–ª–µ –ø–æ –≥–æ—Ç–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–∞–º.",
            invoice_payload = 'basic_invoice_payload',
            start_parameter='subscription',
            provider_token = os.environ['PROVIDE_TOKEN'],
            currency='RUB', prices=price, reply_markup=keyboard)
    
    # Pro tariff
    def Pro_tariff(self, message):
        keyboard = types.InlineKeyboardMarkup()
        keyboard.add(types.InlineKeyboardButton("–ü–æ–¥–∫–ª—é—á–∏—Ç—å —Ç–∞—Ä–∏—Ñ PRO", pay=True))
        keyboard.add(types.InlineKeyboardButton("–ö —Ç–∞—Ä–∏—Ñ–∞–º", callback_data="tariff_exit"))
        price = [types.LabeledPrice(label='PRO', amount=100*100)]
        self.bot.delete_message(chat_id=message.chat.id, message_id=message.message_id)
        self.bot.send_invoice(chat_id=message.chat.id, title = 'PRO',
            description = "–ë–µ–∑–ª–∏–º–∏—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (–≤ —Ç–æ–º —á–∏—Å–ª–µ –ø–æ –≥–æ—Ç–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–∞–º) –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.",
            invoice_payload = 'pro_invoice_payload',
            start_parameter='subscription',
            provider_token = os.environ['PROVIDE_TOKEN'],
            currency='RUB', prices=price, reply_markup=keyboard)
        
    # One text processing
    def TextCommands(self, message, ind: int):
        info = []
        incoming_tokens = 0; outgoing_tokens = 0
        info.append(message.text)
        for i in range(1, len(self.prompts_text['text_list'][ind])):
            msg = self.bot.send_message(chat_id=message.chat.id, text=self.prompts_text['text_list'][ind][i])
            param = None

            def Param_next_step(message):
                nonlocal info, param
                param = message.text
                info.append(param)

            self.bot.register_next_step_handler(msg, Param_next_step)
            while param is None:
                time.sleep(0.5)
        prompt = pc.get_prompt(ind=ind, info=info)
        response, incoming_tokens, outgoing_tokens = self.__gpt_4o_mini(prompt=[{ "role": "user", "content": prompt }], message=message)
        self.restart(message)
        return incoming_tokens, outgoing_tokens, 1
    
    # Some texts processing
    def SomeTextsCommand(self, message, ind: int, tokens: dict[str, int]):
        n = int(message.text)
        text_buttons = [
            "comm-text", "content-plan", "summarization",
            "blog", "longrid", "smm-text", "brainst-text",
            "advertising-text", "headlines-text", "seo-text",
            "news", "editing"
        ]
        ans = []
        avalible = [text_buttons.index(el) for el in [
                                                    "comm-text", "blog", "longrid", "smm-text",
                                                    "advertising-text", "seo-text", "news"
                                                    ]]

        for i in range(n):
            ans.append([])
            if "TEXT" in pc.commands_size[ind]:
                msg = self.bot.send_message(chat_id=message.chat.id, text=f"–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {i+1}")
                text = None
                def Text_next_step(message):
                    nonlocal text, ans
                    text = message.text
                    ans[i].append(text)
                self.bot.register_next_step_handler(msg, Text_next_step)
                while text is None:
                    time.sleep(0.5)
        
        index = avalible.index(ind)
        for el in range(1, len(self.prompts_text["few_texts_list"][index])):
            msg = self.bot.send_message(chat_id=message.chat.id, text=self.prompts_text["few_texts_list"][index][el])
            params = None
            def Params_addition(message):
                nonlocal params, ans
                params = message.text
                params = params.split(';')
                if len(params) < len(pc.commands_size[ind]):
                    while len(params) < len(pc.commands_size[ind]):
                        params.append(None)
                param = params[0]
                [ans[i].append(param) if params[i] is None else ans[i].append(params[i]) for i in range(len(ans))]
            self.bot.register_next_step_handler(msg, Params_addition)
            while params is None:
                time.sleep(0.5)

        incoming_tokens = 0; outgoing_tokens = 0
        def process_prompt(i):
            nonlocal incoming_tokens, outgoing_tokens
            prompt = pc.get_prompt(ind=ind, info=ans[i])
            if tokens['incoming_tokens'] - incoming_tokens > 0 and tokens['outgoing_tokens'] - outgoing_tokens > 0 or tokens['free_requests'] - i > 0:
                response, in_tokens, out_tokens = self.__gpt_4o_mini(prompt=[{"role": "user", "content": prompt}], message=message)
                return in_tokens, out_tokens
            return 0, 0
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            results = list(executor.map(process_prompt, range(n)))
        
        for in_tokens, out_tokens in results:
            incoming_tokens += in_tokens
            outgoing_tokens += out_tokens
        
        self.restart(message)
        return incoming_tokens, outgoing_tokens, n
    
    # Images processing
    def ImageCommand(self, message, prompt: str, size: list[int]):
        seed = randint(1, 1000000)
        self.__FLUX_schnell(prompt=prompt, size=size, message=message, seed=seed, num_inference_steps=4)
        self.ImageChange(message)
        return seed
    
    # Image regeneration and upscaling
    def Image_Regen_And_Upscale(self, message, prompt: str, size: list[int], seed, num_inference_steps=4):
        return self.__FLUX_schnell(prompt=prompt, size=size, message=message, seed=seed, num_inference_steps=num_inference_steps)
    
    # Free mode processing
    def FreeCommand(self, message, prompts: list[str]):
        response, incoming_tokens, outgoing_tokens = self.__gpt_4o_mini(prompt=prompts, message=message, temperature=0.7, top_p=0.85)
        prompts.append({"content": response, "role": "assistant"})
        return incoming_tokens, outgoing_tokens, prompts